{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0822d27d-b304-4538-8d51-21cb16633aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class LogSlowdownTQDM(tqdm):\n",
    "    def __init__(self, iterable=None, *args, fit_every=50, min_points=10, **kwargs):\n",
    "        if iterable is not None and 'total' not in kwargs:\n",
    "            try:\n",
    "                kwargs['total'] = len(iterable)\n",
    "            except TypeError:\n",
    "                pass  # non-sized iterator\n",
    "\n",
    "        super().__init__(iterable=iterable, *args, **kwargs)\n",
    "        self._fit_every = fit_every\n",
    "        self._min_points = min_points\n",
    "        self._timestamps = []\n",
    "        self._iters = []\n",
    "        self._a = 0.001  # sensible default\n",
    "        self._b = 0.0\n",
    "        self._last_fit_iter = 0\n",
    "        self._iterable = iterable\n",
    "\n",
    "    def __iter__(self):\n",
    "        for item in self._iterable:\n",
    "            yield item\n",
    "            self._record_progress()\n",
    "            super().update(1)\n",
    "            self._maybe_refit()\n",
    "            self._show_eta()\n",
    "\n",
    "    def _record_progress(self):\n",
    "        now = time.time()\n",
    "        self._iters.append(self.n + 1)\n",
    "        self._timestamps.append(now)\n",
    "\n",
    "    def _maybe_refit(self):\n",
    "        if self.n >= self._min_points and (self.n - self._last_fit_iter >= self._fit_every):\n",
    "            self._fit_model()\n",
    "            self._last_fit_iter = self.n\n",
    "\n",
    "    def _fit_model(self):\n",
    "        times = np.array(self._timestamps)\n",
    "        iters = np.array(self._iters)\n",
    "\n",
    "        deltas = np.diff(times)  # time per iteration\n",
    "        logs = np.log(np.maximum(iters[1:], 1))  # log(i)\n",
    "\n",
    "        A = np.vstack([np.ones_like(logs), logs]).T\n",
    "        y = deltas\n",
    "\n",
    "        try:\n",
    "            coeffs, _, _, _ = np.linalg.lstsq(A, y, rcond=None)\n",
    "            self._a, self._b = coeffs\n",
    "        except np.linalg.LinAlgError:\n",
    "            pass\n",
    "\n",
    "    def _show_eta(self):\n",
    "        i = self.n\n",
    "        N = self.total\n",
    "        if i < self._min_points or N is None or i >= N:\n",
    "            return\n",
    "\n",
    "        # ∫_i^N (a + b log(x)) dx = a(N - i) + b[N log N - i log i - (N - i)]\n",
    "        try:\n",
    "            log_i = math.log(max(i, 1))\n",
    "            log_N = math.log(N)\n",
    "            eta = (\n",
    "                self._a * (N - i)\n",
    "                + self._b * (N * log_N - i * log_i - (N - i))\n",
    "            )\n",
    "            eta_str = self._format_eta(eta)\n",
    "            self.set_postfix_str(f\"ETA: {eta_str} | a={self._a:.4f}, b={self._b:.4f}\")\n",
    "        except (ValueError, ZeroDivisionError):\n",
    "            pass\n",
    "\n",
    "    def _format_eta(self, seconds: float) -> str:\n",
    "        seconds = int(round(seconds))\n",
    "        days, rem = divmod(seconds, 86400)\n",
    "        hours, rem = divmod(rem, 3600)\n",
    "        minutes, secs = divmod(rem, 60)\n",
    "\n",
    "        parts = []\n",
    "        if days > 0:\n",
    "            parts.append(f\"{days:02}d\")\n",
    "        if hours > 0 or days > 0:\n",
    "            parts.append(f\"{hours:02}h\")\n",
    "        if minutes > 0 or hours > 0 or days > 0:\n",
    "            parts.append(f\"{minutes:02}m\")\n",
    "        parts.append(f\"{secs:02}s\")\n",
    "        return \":\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03f391f-1004-43ce-803b-8ce8b1cb216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "→ Running CIFAR condition: Shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [2:39:28<00:00,  9.57s/it, ETA: 09s | a=11.0337, b=-0.2425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6742\n",
      "→ Running CIFAR condition: Ordered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                  | 339/1000 [49:24<1:36:20,  8.74s/it, ETA: 01h:39m:31s | a=7.8865, b=0.1775]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 190\u001b[0m\n\u001b[0;32m    187\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train_all[idx]\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m→ Running CIFAR condition: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 190\u001b[0m tpr, oi, states, val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_condition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr_hat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mART\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFuzzy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_acc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    199\u001b[0m traces_tpr[order]    \u001b[38;5;241m=\u001b[39m tpr\n",
      "Cell \u001b[1;32mIn[4], line 131\u001b[0m, in \u001b[0;36mrun_condition\u001b[1;34m(X_train, y_train, X_test, y_test, batch_size, rho, r_hat, ART)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_test), \u001b[38;5;241m256\u001b[39m):\n\u001b[0;32m    130\u001b[0m     xb \u001b[38;5;241m=\u001b[39m X_test[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m256\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 131\u001b[0m     logits, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     preds \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    133\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;241m==\u001b[39m y_test[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m256\u001b[39m])\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 69\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     68\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[1;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     70\u001b[0m     z1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x)\n\u001b[0;32m     72\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(z1)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from OverlapIndex import OverlapIndex\n",
    "from OCF import OCF2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# torch.set_num_threads(12)\n",
    "\n",
    "\n",
    "# # ── CNN DEFINITION ────────────────────────────────────────────────\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, 5, padding=2)\n",
    "#         self.pool1 = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, 5, padding=2)\n",
    "#         self.pool2 = nn.MaxPool2d(2, 2)\n",
    "#         self.fc1   = nn.Linear(32 * 8 * 8, 128)\n",
    "#         self.fc2   = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x  = F.relu(self.conv1(x))\n",
    "#         z1 = self.pool1(x)\n",
    "#         x  = F.relu(self.conv2(z1))\n",
    "#         z2 = self.pool2(x)\n",
    "#         flat = z2.view(z2.size(0), -1)\n",
    "#         z3 = F.relu(self.fc1(flat))\n",
    "#         out = self.fc2(z3)\n",
    "#         return out, z1, z2, z3\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn4   = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn5   = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn6   = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        z1 = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(z1)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        z2 = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.bn5(self.conv5(z2)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        z3 = self.pool3(x)\n",
    "\n",
    "        flat = z3.view(z3.size(0), -1)\n",
    "        x = F.relu(self.fc1(flat))\n",
    "        out = self.fc2(x)\n",
    "\n",
    "        return out, z1, z2, z3\n",
    "\n",
    "\n",
    "\n",
    "def run_condition(\n",
    "    X_train: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    X_test:  torch.Tensor,\n",
    "    y_test:  torch.Tensor,\n",
    "    batch_size: int = 50,\n",
    "    rho: float = 0.9,\n",
    "    r_hat: float = 0.1,\n",
    "    ART: str   = \"Fuzzy\"\n",
    ") -> Tuple[List[List[float]], List[float], List[Tuple[float, float]], List[float]]:\n",
    "\n",
    "    model = CNN().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # cf_detector = OCF2(rho=rho, r_hat=r_hat, ART=ART)\n",
    "\n",
    "    tpr_trace: List[List[float]] = []\n",
    "    oi_trace:  List[float] = []\n",
    "    ocf_trace: List[Tuple[float, float]] = []\n",
    "    val_accuracy_trace: List[float] = []\n",
    "\n",
    "    y_test_np = y_test.numpy()\n",
    "    train_ds = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, drop_last=True, shuffle=False)\n",
    "\n",
    "    model.train()\n",
    "    for x_b, y_b in LogSlowdownTQDM(train_ds):\n",
    "        x_b, y_b = x_b.to(device), y_b.to(device)\n",
    "\n",
    "        # 1) forward + backward\n",
    "        out, *_ = model(x_b)\n",
    "        loss = criterion(out, y_b)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 2) eval on full test set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits_test = []\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i in range(0, len(X_test), 256):\n",
    "                xb = X_test[i:i+256].to(device)\n",
    "                logits, *_ = model(xb)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds.cpu() == y_test[i:i+256]).sum().item()\n",
    "                total += preds.size(0)\n",
    "                logits_test.append(logits.cpu())\n",
    "            logits = torch.cat(logits_test).numpy()\n",
    "            val_accuracy = correct / total\n",
    "            val_accuracy_trace.append(val_accuracy)\n",
    "        model.train()\n",
    "\n",
    "        # 3) TPR computation\n",
    "        y_pred = logits.argmax(axis=1)\n",
    "        tprs = []\n",
    "        for cls in range(10):\n",
    "            mask = y_test_np == cls\n",
    "            tp = np.sum(y_pred[mask] == cls)\n",
    "            fn = np.sum(y_pred[mask] != cls)\n",
    "            tprs.append(tp / (tp + fn) if (tp + fn) > 0 else 0.0)\n",
    "        tpr_trace.append(tprs)\n",
    "\n",
    "        # # 4) OCF update\n",
    "        # O, F = cf_detector.add_batch(\n",
    "        #     X_train       = x_b.cpu().numpy().reshape(batch_size, -1),\n",
    "        #     y_train       = y_b.cpu().numpy(),\n",
    "        #     y_pred_eval   = y_pred,\n",
    "        #     y_true_eval   = y_test_np,\n",
    "        #     y_scores_eval = logits\n",
    "        # )\n",
    "        # ocf_trace.append((O, F))\n",
    "        # oi_trace.append(cf_detector.OI.index)\n",
    "\n",
    "    return tpr_trace, oi_trace, ocf_trace, val_accuracy_trace\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_ds = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_ds  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    X_train_all = torch.tensor(train_ds.data).permute(0, 3, 1, 2).float() / 255.0\n",
    "    y_train_all = torch.tensor(train_ds.targets)\n",
    "    X_test      = torch.tensor(test_ds.data).permute(0, 3, 1, 2).float() / 255.0\n",
    "    y_test      = torch.tensor(test_ds.targets)\n",
    "\n",
    "    traces_tpr:     Dict[str, List[List[float]]]         = {}\n",
    "    traces_oi:      Dict[str, List[float]]               = {}\n",
    "    traces_state:   Dict[str, List[Tuple[float, float]]] = {}\n",
    "    val_acc_trace:  Dict[str, List[float]]               = {}\n",
    "\n",
    "    for order in (\"Shuffled\", \"Ordered\"):\n",
    "        if order == \"Shuffled\":\n",
    "            idx = torch.randperm(len(y_train_all))\n",
    "        else:\n",
    "            idx = torch.argsort(y_train_all)\n",
    "\n",
    "        X_train = X_train_all[idx]\n",
    "        y_train = y_train_all[idx]\n",
    "\n",
    "        print(f\"→ Running CIFAR condition: {order}\")\n",
    "        tpr, oi, states, val_acc = run_condition(\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            batch_size=50,\n",
    "            rho=0.9,\n",
    "            r_hat=np.inf,\n",
    "            ART=\"Fuzzy\"\n",
    "        )\n",
    "        print(\"Accuracy:\", val_acc[-1])\n",
    "\n",
    "        traces_tpr[order]    = tpr\n",
    "        traces_oi[order]     = oi\n",
    "        traces_state[order]  = states\n",
    "        val_acc_trace[order] = val_acc\n",
    "\n",
    "    # np.savez(\n",
    "    #     \"cf2_batch_traces_cifar_cnn.npz\",\n",
    "    #     ordered_tpr       = traces_tpr[\"Ordered\"],\n",
    "    #     shuffled_tpr      = traces_tpr[\"Shuffled\"],\n",
    "    #     ordered_int       = traces_oi[\"Ordered\"],\n",
    "    #     shuffled_int      = traces_oi[\"Shuffled\"],\n",
    "    #     ordered_states    = np.array(traces_state[\"Ordered\"]),\n",
    "    #     shuffled_states   = np.array(traces_state[\"Shuffled\"]),\n",
    "    #     ordered_accuracy  = val_acc_trace[\"Ordered\"],\n",
    "    #     shuffled_accuracy = val_acc_trace[\"Shuffled\"]\n",
    "    # )\n",
    "\n",
    "    print(\"Saved CIFAR CNN traces with OCF2, Overlap Index, and per-batch accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba2c619-ca3e-43cf-80da-6717047d085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "→ Running CIFAR condition: Shuffled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4552330448364e9a9429a0fc9d66a23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Running CIFAR condition: Ordered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853ee4630a0e4188a8ce9c928316685b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CIFAR CNN traces with OCF2, Overlap Index, and per-batch accuracy.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# from OverlapIndex import OverlapIndex\n",
    "from OCF import OCF2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn4   = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn5   = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn6   = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        z1 = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(z1)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        z2 = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.bn5(self.conv5(z2)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        z3 = self.pool3(x)\n",
    "\n",
    "        flat = z3.view(z3.size(0), -1)\n",
    "        x = F.relu(self.fc1(flat))\n",
    "        out = self.fc2(x)\n",
    "\n",
    "        return out, z1, z2, z3\n",
    "\n",
    "\n",
    "def run_condition(\n",
    "    X_train: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    X_test:  torch.Tensor,\n",
    "    y_test:  torch.Tensor,\n",
    "    batch_size: int = 50,\n",
    "    sub_batch_size: int = 5,\n",
    "    rho: float = 0.9,\n",
    "    r_hat: float = 0.1,\n",
    "    ART: str   = \"Fuzzy\",\n",
    "    is_ordered: bool = False\n",
    ") -> Tuple[List[List[float]], List[float], List[Tuple[float, float]], List[float]]:\n",
    "\n",
    "    model = CNN().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    cf_detector = OCF2(rho=rho, r_hat=r_hat, ART=ART, match_tracking=\"MT~\")\n",
    "\n",
    "    tpr_trace: List[List[float]] = []\n",
    "    oi_trace:  List[float] = []\n",
    "    ocf_trace: List[Tuple[float, float]] = []\n",
    "    val_accuracy_trace: List[float] = []\n",
    "\n",
    "    y_test_np = y_test.numpy()\n",
    "    train_ds = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, drop_last=True, shuffle=False)\n",
    "\n",
    "    model.train()\n",
    "    last_class_seen = -1\n",
    "    for x_b, y_b in tqdm(train_ds):\n",
    "        x_b, y_b = x_b.to(device), y_b.to(device)\n",
    "\n",
    "        if is_ordered:\n",
    "        # Determine the dominant class in the batch\n",
    "            current_class = y_b[0].item()  # assuming ordered and pure batches\n",
    "            if current_class != last_class_seen:\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # reset optimizer\n",
    "                last_class_seen = current_class\n",
    "    \n",
    "        \n",
    "        prev_loss = float(\"inf\")\n",
    "        for _ in range(10):  # set a max to avoid infinite loops\n",
    "            model.train()\n",
    "            out, *_ = model(x_b)\n",
    "            loss = criterion(out, y_b)\n",
    "    \n",
    "            # Check convergence\n",
    "            if abs(prev_loss - loss.item()) < 1e-4:\n",
    "                break\n",
    "            prev_loss = loss.item()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 2) eval on full test set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits_test = []\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i in range(0, len(X_test), 256):\n",
    "                xb = X_test[i:i+256].to(device)\n",
    "                logits, *_ = model(xb)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds.cpu() == y_test[i:i+256]).sum().item()\n",
    "                total += preds.size(0)\n",
    "                logits_test.append(logits.cpu())\n",
    "            logits = torch.cat(logits_test).numpy()\n",
    "            val_accuracy = correct / total\n",
    "            val_accuracy_trace.append(val_accuracy)\n",
    "        model.train()\n",
    "\n",
    "        # 3) TPR computation\n",
    "        y_pred = logits.argmax(axis=1)\n",
    "        tprs = []\n",
    "        for cls in range(10):\n",
    "            mask = y_test_np == cls\n",
    "            tp = np.sum(y_pred[mask] == cls)\n",
    "            fn = np.sum(y_pred[mask] != cls)\n",
    "            tprs.append(tp / (tp + fn) if (tp + fn) > 0 else 0.0)\n",
    "        tpr_trace.append(tprs)\n",
    "\n",
    "        indices = np.random.choice(batch_size, sub_batch_size, replace=False)\n",
    "        \n",
    "        # 4) OCF update with subsampled data\n",
    "        O, F = cf_detector.add_batch(\n",
    "            X_train       = x_b[indices].cpu().numpy().reshape(sub_batch_size, -1),\n",
    "            y_train       = y_b[indices].cpu().numpy(),\n",
    "            y_pred_eval   = y_pred,\n",
    "            y_true_eval   = y_test_np,\n",
    "            y_scores_eval = logits\n",
    "        )\n",
    "        ocf_trace.append((O, F))\n",
    "        oi_trace.append(cf_detector.OI.index)\n",
    "\n",
    "    return tpr_trace, oi_trace, ocf_trace, val_accuracy_trace\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_ds = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_ds  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    X_train_all = torch.tensor(train_ds.data).permute(0, 3, 1, 2).float() / 255.0\n",
    "    y_train_all = torch.tensor(train_ds.targets)\n",
    "    X_test      = torch.tensor(test_ds.data).permute(0, 3, 1, 2).float() / 255.0\n",
    "    y_test      = torch.tensor(test_ds.targets)\n",
    "\n",
    "    traces_tpr:     Dict[str, List[List[float]]]         = {}\n",
    "    traces_oi:      Dict[str, List[float]]               = {}\n",
    "    traces_state:   Dict[str, List[Tuple[float, float]]] = {}\n",
    "    val_acc_trace:  Dict[str, List[float]]               = {}\n",
    "\n",
    "    for order in (\"Shuffled\", \"Ordered\"):\n",
    "        if order == \"Shuffled\":\n",
    "            idx = torch.randperm(len(y_train_all))\n",
    "        else:\n",
    "            idx = torch.argsort(y_train_all)\n",
    "\n",
    "        X_train = X_train_all[idx]\n",
    "        y_train = y_train_all[idx]\n",
    "\n",
    "        print(f\"→ Running CIFAR condition: {order}\")\n",
    "        tpr, oi, states, val_acc = run_condition(\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            batch_size=250,\n",
    "            sub_batch_size = 25,\n",
    "            rho=0.9,\n",
    "            r_hat=np.inf,\n",
    "            ART=\"Fuzzy\",\n",
    "            is_ordered=(order == \"Ordered\")\n",
    "        )\n",
    "\n",
    "        traces_tpr[order]    = tpr\n",
    "        traces_oi[order]     = oi\n",
    "        traces_state[order]  = states\n",
    "        val_acc_trace[order] = val_acc\n",
    "\n",
    "    np.savez(\n",
    "        \"cf2_batch_traces_cifar_cnn_4.npz\",\n",
    "        ordered_tpr       = traces_tpr[\"Ordered\"],\n",
    "        shuffled_tpr      = traces_tpr[\"Shuffled\"],\n",
    "        ordered_int       = traces_oi[\"Ordered\"],\n",
    "        shuffled_int      = traces_oi[\"Shuffled\"],\n",
    "        ordered_states    = np.array(traces_state[\"Ordered\"]),\n",
    "        shuffled_states   = np.array(traces_state[\"Shuffled\"]),\n",
    "        ordered_accuracy  = val_acc_trace[\"Ordered\"],\n",
    "        shuffled_accuracy = val_acc_trace[\"Shuffled\"]\n",
    "    )\n",
    "\n",
    "    print(\"Saved CIFAR CNN traces with OCF2, Overlap Index, and per-batch accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ad13e-1c9b-4c52-9f84-eeeb4598f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "→ Running CIFAR condition: Shuffled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f03d7b48d5425da4324a4a76084a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Running CIFAR condition: Ordered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99eb6bdc23c4a02a28511aa08895d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from ActivationKNN import KNN\n",
    "from typing import List, Tuple, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from OverlapIndex import OverlapIndex\n",
    "from OCF import OCF2\n",
    "\n",
    "\n",
    "def run_condition_knn(\n",
    "    X_train: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    X_test:  torch.Tensor,\n",
    "    y_test:  torch.Tensor,\n",
    "    batch_size: int = 50,\n",
    "    sub_batch_size: int = 5,\n",
    "    rho: float = 0.9,\n",
    "    r_hat: float = 0.1,\n",
    "    ART: str   = \"Fuzzy\"\n",
    ") -> Tuple[List[List[float]], List[float], List[Tuple[float, float]], List[float]]:\n",
    "\n",
    "    clf = KNN(n_neighbors=1)\n",
    "    cf_detector = OCF2(rho=rho, r_hat=r_hat, ART=ART, match_tracking=\"MT~\")\n",
    "\n",
    "    tpr_trace: List[List[float]] = []\n",
    "    oi_trace:  List[float] = []\n",
    "    ocf_trace: List[Tuple[float, float]] = []\n",
    "    val_accuracy_trace: List[float] = []\n",
    "\n",
    "    y_test_np = y_test.numpy()\n",
    "    X_test_np = X_test.reshape(len(X_test), -1).numpy()\n",
    "\n",
    "    # Incremental \"fitting\" by re-training KNN on accumulating data\n",
    "    X_seen = []\n",
    "    y_seen = []\n",
    "\n",
    "    train_ds = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, drop_last=True, shuffle=False)\n",
    "\n",
    "    for x_b, y_b in tqdm(train_ds):\n",
    "        x_b_np = x_b.reshape(batch_size, -1).numpy()\n",
    "        y_b_np = y_b.numpy()\n",
    "\n",
    "        # Accumulate training data\n",
    "        X_seen.append(x_b_np)\n",
    "        y_seen.append(y_b_np)\n",
    "\n",
    "        X_seen_np = np.vstack(X_seen)\n",
    "        y_seen_np = np.concatenate(y_seen)\n",
    "\n",
    "        # Train KNN on accumulated data\n",
    "        clf.fit(X_seen_np, y_seen_np)\n",
    "\n",
    "        # 1) evaluate\n",
    "        y_pred = clf.predict(X_test_np)\n",
    "        val_accuracy = np.mean(y_pred == y_test_np)\n",
    "        val_accuracy_trace.append(val_accuracy)\n",
    "\n",
    "        # 2) compute TPR\n",
    "        tprs = []\n",
    "        for cls in range(10):\n",
    "            mask = y_test_np == cls\n",
    "            tp = np.sum(y_pred[mask] == cls)\n",
    "            fn = np.sum(y_pred[mask] != cls)\n",
    "            tprs.append(tp / (tp + fn) if (tp + fn) > 0 else 0.0)\n",
    "        tpr_trace.append(tprs)\n",
    "\n",
    "        indices = np.random.choice(batch_size, sub_batch_size, replace=False)\n",
    "\n",
    "        # 3) compute OCF indices\n",
    "        y_scores = clf.activation(X_test_np)\n",
    "        O, F = cf_detector.add_batch(\n",
    "            X_train       = x_b_np[indices].reshape(sub_batch_size, -1),\n",
    "            y_train       = y_b_np[indices],\n",
    "            y_pred_eval   = y_pred,\n",
    "            y_true_eval   = y_test_np,\n",
    "            y_scores_eval = y_scores\n",
    "        )\n",
    "        ocf_trace.append((O, F))\n",
    "        oi_trace.append(cf_detector.OI.index)\n",
    "\n",
    "    return tpr_trace, oi_trace, ocf_trace, val_accuracy_trace\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_ds = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_ds  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    X_train_all = torch.tensor(train_ds.data).permute(0, 3, 1, 2).float() / 255.0\n",
    "    y_train_all = torch.tensor(train_ds.targets)\n",
    "    X_test      = torch.tensor(test_ds.data).permute(0, 3, 1, 2).float() / 255.0\n",
    "    y_test      = torch.tensor(test_ds.targets)\n",
    "\n",
    "    traces_tpr:     Dict[str, List[List[float]]]         = {}\n",
    "    traces_oi:      Dict[str, List[float]]               = {}\n",
    "    traces_state:   Dict[str, List[Tuple[float, float]]] = {}\n",
    "    val_acc_trace:  Dict[str, List[float]]               = {}\n",
    "\n",
    "    for order in (\"Shuffled\", \"Ordered\"):\n",
    "        if order == \"Shuffled\":\n",
    "            idx = torch.randperm(len(y_train_all))\n",
    "        else:\n",
    "            idx = torch.argsort(y_train_all)\n",
    "\n",
    "        X_train = X_train_all[idx]\n",
    "        y_train = y_train_all[idx]\n",
    "\n",
    "        print(f\"→ Running CIFAR condition: {order}\")\n",
    "        tpr, oi, states, val_acc = run_condition_knn(\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            batch_size=250,\n",
    "            sub_batch_size = 25,\n",
    "            rho=0.9,\n",
    "            r_hat=np.inf,\n",
    "            ART=\"Fuzzy\"\n",
    "        )\n",
    "\n",
    "        traces_tpr[order]    = tpr\n",
    "        traces_oi[order]     = oi\n",
    "        traces_state[order]  = states\n",
    "        val_acc_trace[order] = val_acc\n",
    "\n",
    "    np.savez(\n",
    "        \"cf2_batch_traces_cifar_knn_4.npz\",\n",
    "        ordered_tpr       = traces_tpr[\"Ordered\"],\n",
    "        shuffled_tpr      = traces_tpr[\"Shuffled\"],\n",
    "        ordered_int       = traces_oi[\"Ordered\"],\n",
    "        shuffled_int      = traces_oi[\"Shuffled\"],\n",
    "        ordered_states    = np.array(traces_state[\"Ordered\"]),\n",
    "        shuffled_states   = np.array(traces_state[\"Shuffled\"]),\n",
    "        ordered_accuracy  = val_acc_trace[\"Ordered\"],\n",
    "        shuffled_accuracy = val_acc_trace[\"Shuffled\"]\n",
    "    )\n",
    "\n",
    "    print(\"Saved CIFAR KNN traces with OCF2, Overlap Index, and per-batch accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a9061-5516-44f8-97dc-3a3a1eb28e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "cnn_data = np.load(\"cf2_batch_traces_cifar_cnn_4.npz\", allow_pickle=True)\n",
    "knn_data = np.load(\"cf2_batch_traces_cifar_knn_4.npz\", allow_pickle=True)\n",
    "\n",
    "methods = [\"CNN\", \"KNN\"]\n",
    "datasets = [cnn_data, knn_data]\n",
    "orders = [\"ordered\", \"shuffled\"]\n",
    "colors = plt.cm.tab10.colors\n",
    "class_labels = [f\"Class {i} TPR\" for i in range(10)]\n",
    "\n",
    "# === Mosaic Layout with Spacer ===\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "mosaic = [\n",
    "    [\"A\", \"B\"],   # Ordered\n",
    "    [\".\", \".\"],   # Spacer\n",
    "    [\"C\", \"D\"],   # Shuffled (Top)\n",
    "    [\"E\", \"F\"]    # Shuffled (Bottom)\n",
    "]\n",
    "ax_dict = fig.subplot_mosaic(mosaic, height_ratios=[1.5, 0.1, 0.7, 0.5])\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.25, top=0.84, bottom=0.07)  # reserve top space\n",
    "\n",
    "# Legend handles\n",
    "tpr_lines = []\n",
    "metric_lines = []\n",
    "metric_labels = []\n",
    "\n",
    "# === Plotting ===\n",
    "for col, (method, data) in enumerate(zip(methods, datasets)):\n",
    "    for row, order in enumerate(orders):\n",
    "        prefix = order\n",
    "        tpr = data[f\"{prefix}_tpr\"]\n",
    "        acc = data[f\"{prefix}_accuracy\"]\n",
    "        ocf = data[f\"{prefix}_states\"]\n",
    "        x = np.arange(len(acc))\n",
    "\n",
    "        if row == 0:\n",
    "            ax = ax_dict[[\"A\", \"B\"][col]]\n",
    "            ax2 = ax.twinx()\n",
    "        else:\n",
    "            ax_top = ax_dict[[\"C\", \"D\"][col]]\n",
    "            ax_bot = ax_dict[[\"E\", \"F\"][col]]\n",
    "            ax = ax_top\n",
    "            ax2 = ax_top.twinx()\n",
    "            ax_bot2 = ax_bot.twinx()\n",
    "\n",
    "            # Broken axis setup\n",
    "            ax_top.spines['bottom'].set_visible(False)\n",
    "            ax_bot.spines['top'].set_visible(False)\n",
    "            ax_top.tick_params(labeltop=False)\n",
    "            ax_top.set_xticklabels([])\n",
    "            ax_bot.xaxis.tick_bottom()\n",
    "\n",
    "            # Diagonal break markers\n",
    "            kwargs = dict(transform=ax_top.transAxes, color='k', clip_on=False)\n",
    "            ax_top.plot((-0.01, +0.01), (-0.015, +0.015), **kwargs)\n",
    "            ax_top.plot((0.99, 1.01), (-0.015, +0.015), **kwargs)\n",
    "            kwargs.update(transform=ax_bot.transAxes)\n",
    "            ax_bot.plot((-0.01, +0.01), (1 - 0.015, 1 + 0.015), **kwargs)\n",
    "            ax_bot.plot((0.99, 1.01), (1 - 0.015, 1 + 0.015), **kwargs)\n",
    "\n",
    "        # Plot TPRs\n",
    "        for i in range(10):\n",
    "            line, = ax.plot(x, tpr[:, i], color=colors[i], linewidth=1, alpha=0.7)\n",
    "            if row == 0 and col == 0:\n",
    "                tpr_lines.append(line)\n",
    "\n",
    "        # Accuracy and OCF2\n",
    "        acc_line, = ax.plot(x, acc, color=\"black\", linewidth=2)\n",
    "        o_line, = ax2.plot(x, ocf[:, 0], linestyle=\"--\", color=\"darkred\", linewidth=2)\n",
    "        f_line, = ax2.plot(x, ocf[:, 1], linestyle=\"-.\", color=\"darkblue\", linewidth=2)\n",
    "\n",
    "        if row == 1:\n",
    "            ax_bot.plot(x, acc, color=\"black\", linewidth=2)\n",
    "            ax_bot2.plot(x, ocf[:, 0], linestyle=\"--\", color=\"darkred\", linewidth=2)\n",
    "            ax_bot2.plot(x, ocf[:, 1], linestyle=\"-.\", color=\"darkblue\", linewidth=2)\n",
    "\n",
    "            ax.set_ylim(0.6, 1.0)\n",
    "            ax2.set_ylim(0.6, 1.0)\n",
    "            ax_bot.set_ylim(0.0, 0.2)\n",
    "            ax_bot2.set_ylim(0.0, 0.2)\n",
    "\n",
    "            # Centered Y-labels at break\n",
    "            # ax.text(-0.08, 0.5, \"TPR / Accuracy\", transform=ax.transAxes,\n",
    "            #         rotation=90, va='center', ha='center', fontsize=10)\n",
    "            # ax2.text(1.08, 0.5, \"O / F\", transform=ax2.transAxes,\n",
    "            #          rotation=90, va='center', ha='center', fontsize=10)\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(\"TPR / Accuracy\")\n",
    "            if col == 1:\n",
    "                ax2.set_ylabel(\"O / F\")\n",
    "        else:\n",
    "            ax.set_ylim(0, 1.05)\n",
    "            ax2.set_ylim(0, 1.05)\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(\"TPR / Accuracy\")\n",
    "            if col == 1:\n",
    "                ax2.set_ylabel(\"O / F\")\n",
    "\n",
    "        # Titles and x-labels\n",
    "        ax.set_title(f\"{method} - {order.capitalize()}\", fontsize=12)\n",
    "        if row == 1:\n",
    "            ax_bot.set_xlabel(\"Batch Index\")\n",
    "        elif row == 3:\n",
    "            ax.set_xlabel(\"Batch Index\")\n",
    "\n",
    "        if row == 0 and col == 0:\n",
    "            metric_lines = [acc_line, o_line, f_line]\n",
    "            metric_labels = [\"Accuracy\", \"Overshadowing\", \"Forgetting\"]\n",
    "\n",
    "# === Legends (Side-by-side, Centered, Equal Height) ===\n",
    "legend_y = 0.965\n",
    "legend_x_offset = 0.425\n",
    "fig.legend(tpr_lines, class_labels,\n",
    "           loc=\"upper center\", bbox_to_anchor=(legend_x_offset, legend_y),\n",
    "           fontsize=9, title=\"Class True-Positive Rates\", ncol=5, frameon=True)\n",
    "fig.legend(metric_lines, metric_labels,\n",
    "           loc=\"upper center\", bbox_to_anchor=(legend_x_offset+0.33, legend_y),\n",
    "           fontsize=9, title=\"Global Metrics\", ncol=2, frameon=True)\n",
    "plt.savefig(\"figures/CIFAR_OFI_CNN_KNN_2.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6daa22-8fc2-41ce-a5b5-48c21e1e913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "→ Running CIFAR condition: Shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                    | 279/1000 [2:03:40<5:19:36, 26.60s/it, ETA: 08h:13m:59s | a=-17.5671, b=9.1656]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 173\u001b[0m\n\u001b[0;32m    170\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train_all[idx]\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m→ Running CIFAR condition: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 173\u001b[0m tpr, oi, states, val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_condition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr_hat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mART\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFuzzy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m traces_tpr[order]    \u001b[38;5;241m=\u001b[39m tpr\n\u001b[0;32m    182\u001b[0m traces_oi[order]     \u001b[38;5;241m=\u001b[39m oi\n",
      "Cell \u001b[1;32mIn[5], line 135\u001b[0m, in \u001b[0;36mrun_condition\u001b[1;34m(X_train, y_train, X_test, y_test, batch_size, rho, r_hat, ART)\u001b[0m\n\u001b[0;32m    132\u001b[0m tpr_trace\u001b[38;5;241m.\u001b[39mappend(tprs)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# 4) OCF update\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m O, F \u001b[38;5;241m=\u001b[39m \u001b[43mcf_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred_eval\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true_eval\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_test_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_scores_eval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m ocf_trace\u001b[38;5;241m.\u001b[39mappend((O, F))\n\u001b[0;32m    143\u001b[0m oi_trace\u001b[38;5;241m.\u001b[39mappend(cf_detector\u001b[38;5;241m.\u001b[39mOI\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mF:\\ACIL stuff\\Code\\CVI_Forgetting\\OCF.py:203\u001b[0m, in \u001b[0;36madd_batch\u001b[1;34m(self, X_train, y_train, y_pred_eval, y_true_eval, y_scores_eval)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mF:\\ACIL stuff\\Code\\CVI_Forgetting\\OverlapIndex.py:156\u001b[0m, in \u001b[0;36madd_batch\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mF:\\ACIL stuff\\Code\\CVI_Forgetting\\OverlapIndex.py:105\u001b[0m, in \u001b[0;36mpredict_subset_pairs\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_subset_pairs\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_a\u001b[38;5;241m.\u001b[39mW) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mART module is not fit.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m     T, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_a\u001b[38;5;241m.\u001b[39mcategory_choice(x, w, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_a\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_a\u001b[38;5;241m.\u001b[39mW\n\u001b[0;32m    109\u001b[0m     ])\n\u001b[0;32m    110\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrev_map\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# from OverlapIndex import OverlapIndex\n",
    "from OCF import OCF2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# # ── CNN DEFINITION ────────────────────────────────────────────────\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, 5, padding=2)\n",
    "#         self.pool1 = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, 5, padding=2)\n",
    "#         self.pool2 = nn.MaxPool2d(2, 2)\n",
    "#         self.fc1   = nn.Linear(32 * 8 * 8, 128)\n",
    "#         self.fc2   = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x  = F.relu(self.conv1(x))\n",
    "#         z1 = self.pool1(x)\n",
    "#         x  = F.relu(self.conv2(z1))\n",
    "#         z2 = self.pool2(x)\n",
    "#         flat = z2.view(z2.size(0), -1)\n",
    "#         z3 = F.relu(self.fc1(flat))\n",
    "#         out = self.fc2(z3)\n",
    "#         return out, z1, z2, z3\n",
    "\n",
    "class OptimizedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x  = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        z1 = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x  = self.pool(F.relu(self.bn3(self.conv3(z1))))\n",
    "        z2 = x\n",
    "        flat = z2.view(z2.size(0), -1)\n",
    "        z3 = F.relu(self.fc1(flat))\n",
    "        z3 = self.dropout(z3)\n",
    "        out = self.fc2(z3)\n",
    "        return out, z1, z2, z3\n",
    "\n",
    "\n",
    "def run_condition(\n",
    "    X_train: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    X_test:  torch.Tensor,\n",
    "    y_test:  torch.Tensor,\n",
    "    batch_size: int = 50,\n",
    "    rho: float = 0.8,\n",
    "    r_hat: float = 0.1,\n",
    "    ART: str   = \"Fuzzy\"\n",
    ") -> Tuple[List[List[float]], List[float], List[Tuple[float, float]], List[float]]:\n",
    "\n",
    "    model = CNN().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    cf_detector = OCF2(rho=rho, r_hat=r_hat, ART=ART)\n",
    "\n",
    "    tpr_trace: List[List[float]] = []\n",
    "    oi_trace:  List[float] = []\n",
    "    ocf_trace: List[Tuple[float, float]] = []\n",
    "    val_accuracy_trace: List[float] = []\n",
    "\n",
    "    y_test_np = y_test.numpy()\n",
    "    train_ds = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, drop_last=True, shuffle=False)\n",
    "\n",
    "    model.train()\n",
    "    for x_b, y_b in LogSlowdownTQDM(train_ds):\n",
    "        x_b, y_b = x_b.to(device), y_b.to(device)\n",
    "\n",
    "        # 1) forward + backward\n",
    "        out, *_ = model(x_b)\n",
    "        loss = criterion(out, y_b)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 2) eval on full test set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits_test = []\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i in range(0, len(X_test), 256):\n",
    "                xb = X_test[i:i+256].to(device)\n",
    "                logits, *_ = model(xb)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds.cpu() == y_test[i:i+256]).sum().item()\n",
    "                total += preds.size(0)\n",
    "                logits_test.append(logits.cpu())\n",
    "            logits = torch.cat(logits_test).numpy()\n",
    "            val_accuracy = correct / total\n",
    "            val_accuracy_trace.append(val_accuracy)\n",
    "        model.train()\n",
    "\n",
    "        # 3) TPR computation\n",
    "        y_pred = logits.argmax(axis=1)\n",
    "        tprs = []\n",
    "        for cls in range(10):\n",
    "            mask = y_test_np == cls\n",
    "            tp = np.sum(y_pred[mask] == cls)\n",
    "            fn = np.sum(y_pred[mask] != cls)\n",
    "            tprs.append(tp / (tp + fn) if (tp + fn) > 0 else 0.0)\n",
    "        tpr_trace.append(tprs)\n",
    "\n",
    "        # 4) OCF update\n",
    "        O, F = cf_detector.add_batch(\n",
    "            X_train       = x_b.cpu().numpy().reshape(batch_size, -1),\n",
    "            y_train       = y_b.cpu().numpy(),\n",
    "            y_pred_eval   = y_pred,\n",
    "            y_true_eval   = y_test_np,\n",
    "            y_scores_eval = logits\n",
    "        )\n",
    "        ocf_trace.append((O, F))\n",
    "        oi_trace.append(cf_detector.OI.index)\n",
    "\n",
    "    return tpr_trace, oi_trace, ocf_trace, val_accuracy_trace\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_ds = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_ds  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    X_train_all = torch.tensor(train_ds.data).permute(0, 3, 1, 2).float() / 255.0\n",
    "    y_train_all = torch.tensor(train_ds.targets)\n",
    "    X_test      = torch.tensor(test_ds.data).permute(0, 3, 1, 2).float() / 255.0\n",
    "    y_test      = torch.tensor(test_ds.targets)\n",
    "\n",
    "    traces_tpr:     Dict[str, List[List[float]]]         = {}\n",
    "    traces_oi:      Dict[str, List[float]]               = {}\n",
    "    traces_state:   Dict[str, List[Tuple[float, float]]] = {}\n",
    "    val_acc_trace:  Dict[str, List[float]]               = {}\n",
    "\n",
    "    for order in (\"Shuffled\", \"Ordered\"):\n",
    "        if order == \"Shuffled\":\n",
    "            idx = torch.randperm(len(y_train_all))\n",
    "        else:\n",
    "            idx = torch.argsort(y_train_all)\n",
    "\n",
    "        X_train = X_train_all[idx]\n",
    "        y_train = y_train_all[idx]\n",
    "\n",
    "        print(f\"→ Running CIFAR condition: {order}\")\n",
    "        tpr, oi, states, val_acc = run_condition(\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            batch_size=50,\n",
    "            rho=0.9,\n",
    "            r_hat=np.inf,\n",
    "            ART=\"Fuzzy\"\n",
    "        )\n",
    "\n",
    "        traces_tpr[order]    = tpr\n",
    "        traces_oi[order]     = oi\n",
    "        traces_state[order]  = states\n",
    "        val_acc_trace[order] = val_acc\n",
    "\n",
    "    np.savez(\n",
    "        \"cf2_batch_traces_cifar_cnn_2.npz\",\n",
    "        ordered_tpr       = traces_tpr[\"Ordered\"],\n",
    "        shuffled_tpr      = traces_tpr[\"Shuffled\"],\n",
    "        ordered_int       = traces_oi[\"Ordered\"],\n",
    "        shuffled_int      = traces_oi[\"Shuffled\"],\n",
    "        ordered_states    = np.array(traces_state[\"Ordered\"]),\n",
    "        shuffled_states   = np.array(traces_state[\"Shuffled\"]),\n",
    "        ordered_accuracy  = val_acc_trace[\"Ordered\"],\n",
    "        shuffled_accuracy = val_acc_trace[\"Shuffled\"]\n",
    "    )\n",
    "\n",
    "    print(\"Saved CIFAR CNN traces with OCF2, Overlap Index, and per-batch accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea748599-ea86-4f12-9b2a-ae4f1faf9df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
