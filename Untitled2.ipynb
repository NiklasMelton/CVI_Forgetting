{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6adeee1-a73f-43e4-8e62-dd84872bcada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niklasmelton/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9799 - loss: 0.0762\n",
      "Epoch 2/5\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0020\n",
      "Epoch 3/5\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 9.2832e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.4517e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.9795e-04\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Phase classes [2, 3]: 12089 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c5f2d3ef6243b9bc81e09328bb8347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DS-AL update:   0%|          | 0/12089 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase classes [4, 5]: 11263 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d035a51ab84ca7bf78831d081cd52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DS-AL update:   0%|          | 0/11263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase classes [6, 7]: 12183 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a577ebb1aa4f859ebcac4fa26689c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DS-AL update:   0%|          | 0/12183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase classes [8, 9]: 11800 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25805dc2095480da22631b593fc144d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DS-AL update:   0%|          | 0/11800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\n",
      "Final MNIST accuracy: 9.87%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class DSAL:\n",
    "    \"\"\"\n",
    "    Dual-Stream Analytic Learning (DS-AL)\n",
    "      • Main stream: recursive least squares (RLS) linear mapping.\n",
    "      • Compensation stream: RLS on the null-space residuals.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features: int, n_classes: int, lambda_: float = 1e-3):\n",
    "        self.n_features = n_features\n",
    "        self.n_classes  = n_classes\n",
    "        self.lambda_    = lambda_\n",
    "\n",
    "        # main-stream RLS state\n",
    "        self.W_main = np.zeros((n_classes, n_features))\n",
    "        self.P_main = (1.0 / lambda_) * np.eye(n_features)\n",
    "\n",
    "        # compensation-stream RLS state\n",
    "        self.W_c = np.zeros((n_classes, n_features))\n",
    "        self.P_c = (1.0 / lambda_) * np.eye(n_features)\n",
    "\n",
    "    def update(self, X: np.ndarray, Y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Per-sample RLS update on both streams.\n",
    "        X: (n_samples, n_features)\n",
    "        Y: (n_samples, n_classes) one-hot\n",
    "        \"\"\"\n",
    "        for x_i, y_i in tqdm(zip(X, Y), total=len(X), desc=\"DS-AL update\"):\n",
    "            x = x_i[:, None]  # (d,1)\n",
    "            y = y_i[:, None]  # (C,1)\n",
    "\n",
    "            # ——— 1) main-stream RLS ———\n",
    "            P_x    = self.P_main @ x\n",
    "            denom  = 1.0 + (x.T @ P_x).item()\n",
    "            k_main = P_x / denom\n",
    "            e_main = y - (self.W_main @ x)\n",
    "\n",
    "            self.W_main += e_main @ k_main.T\n",
    "            self.P_main  -= k_main @ (x.T @ self.P_main)\n",
    "\n",
    "            # compute null-space projector of W_main\n",
    "            W_pinv = np.linalg.pinv(self.W_main)\n",
    "            P_ker  = np.eye(self.n_features) - W_pinv @ self.W_main\n",
    "            x_proj = P_ker @ x\n",
    "\n",
    "            # ——— 2) compensation-stream RLS ———\n",
    "            res    = y - (self.W_main @ x)\n",
    "            Pcx    = self.P_c @ x_proj\n",
    "            denom_c = 1.0 + (x_proj.T @ Pcx).item()\n",
    "            k_c    = Pcx / denom_c\n",
    "\n",
    "            self.W_c += res @ k_c.T\n",
    "            self.P_c  -= k_c @ (x_proj.T @ self.P_c)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        f(x) = W_main x + W_c (P_ker x)\n",
    "        Returns logits of shape (n_samples, n_classes).\n",
    "        \"\"\"\n",
    "        W_pinv = np.linalg.pinv(self.W_main)\n",
    "        P_ker  = np.eye(self.n_features) - W_pinv @ self.W_main\n",
    "\n",
    "        Y_main = X @ self.W_main.T\n",
    "        Y_comp = (X @ P_ker) @ self.W_c.T\n",
    "        return Y_main + Y_comp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Load & normalize MNIST\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train[..., None] / 255.0\n",
    "    x_test  = x_test[..., None]  / 255.0\n",
    "\n",
    "    # 2) One-hot over all 10 digits\n",
    "    encoder     = OneHotEncoder(sparse_output=False)\n",
    "    Y_train_all = encoder.fit_transform(y_train[:, None])\n",
    "    Y_test_all  = encoder.transform(y_test[:, None])\n",
    "\n",
    "    # 3) Define phases: base = [0,1], then [2,3], [4,5], [6,7], [8,9]\n",
    "    phases = [[0,1], [2,3], [4,5], [6,7], [8,9]]\n",
    "\n",
    "    # 4) BP-train CNN on the base phase\n",
    "    base_classes = phases[0]\n",
    "    mask0 = np.isin(y_train, base_classes)\n",
    "    X0, y0 = x_train[mask0], y_train[mask0]\n",
    "    Y0_small = np.stack([(y0 == c).astype(float) for c in base_classes], axis=1)\n",
    "\n",
    "    model_cnn = Sequential([\n",
    "        InputLayer(input_shape=(28,28,1)),\n",
    "        Conv2D(32, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(name=\"flatten\"),\n",
    "        Dense(128, activation=\"relu\", name=\"fc1\"),\n",
    "        Dense(len(base_classes), activation=\"softmax\", name=\"clf\")\n",
    "    ])\n",
    "    model_cnn.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss=CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model_cnn.fit(\n",
    "        X0, Y0_small,\n",
    "        epochs=5,\n",
    "        batch_size=64,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 5) Freeze backbone up to the Flatten layer by rebuilding functionally\n",
    "    inp = Input(shape=(28,28,1))\n",
    "    x   = inp\n",
    "    for layer in model_cnn.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name == \"flatten\":\n",
    "            break\n",
    "    backbone = Model(inputs=inp, outputs=x)\n",
    "    d_cnn = backbone.output_shape[1]  # e.g. 7*7*64 = 3136\n",
    "\n",
    "    # 6) Build random-projection buffer B: ℝ^{d_cnn→d_B}\n",
    "    d_B = 512\n",
    "    B   = np.random.randn(d_cnn, d_B)\n",
    "\n",
    "    # 7) Extract & buffer base features\n",
    "    X0_feat = backbone.predict(X0, batch_size=256)\n",
    "    X0_buf  = np.maximum(0, X0_feat @ B)\n",
    "    Y0_full = Y_train_all[mask0]\n",
    "\n",
    "    # 8) Closed-form ridge solution for W_main^(0)\n",
    "    λ  = 1e-3\n",
    "    R0 = np.linalg.inv(X0_buf.T @ X0_buf + λ * np.eye(d_B))\n",
    "    W0 = (R0 @ X0_buf.T @ Y0_full).T\n",
    "\n",
    "    # 9) Instantiate DS-AL and inject initial state\n",
    "    model = DSAL(n_features=d_B, n_classes=10, lambda_=λ)\n",
    "    model.W_main = W0.copy()\n",
    "    model.P_main = R0.copy()\n",
    "    # W_c and P_c remain at default\n",
    "\n",
    "    # 10) Prepare buffered feature tasks for phases 1–4\n",
    "    tasks = []\n",
    "    for cls_grp in phases[1:]:\n",
    "        mask = np.isin(y_train, cls_grp)\n",
    "        Xf   = backbone.predict(x_train[mask], batch_size=256)\n",
    "        Xb   = np.maximum(0, Xf @ B)\n",
    "        Yb   = Y_train_all[mask]\n",
    "        tasks.append((cls_grp, Xb, Yb))\n",
    "\n",
    "    # 11) Incremental RLS on phases 1–4\n",
    "    for cls_grp, Xb, Yb in tasks:\n",
    "        Xb, Yb = shuffle(Xb, Yb, random_state=42)\n",
    "        print(f\"Phase classes {cls_grp}: {Xb.shape[0]} samples\")\n",
    "        model.update(Xb, Yb)\n",
    "\n",
    "    # 12) Final evaluation on full test set\n",
    "    X_test_feat = backbone.predict(x_test, batch_size=256)\n",
    "    X_test_buf  = np.maximum(0, X_test_feat @ B)\n",
    "    logits      = model.predict(X_test_buf)\n",
    "    y_pred      = np.argmax(logits, axis=1)\n",
    "    acc         = (y_pred == y_test).mean()\n",
    "\n",
    "    print(f\"\\nFinal MNIST accuracy: {acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2d647-946b-4b50-91bb-f58b4a3ff589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
